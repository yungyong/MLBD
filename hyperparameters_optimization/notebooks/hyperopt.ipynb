{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Spark-MLlib-Tuning\" data-toc-modified-id=\"Spark-MLlib-Tuning-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-tuning.html\" target=\"_blank\">Spark MLlib Tuning</a></a></span></li><li><span><a href=\"#Hyperopt\" data-toc-modified-id=\"Hyperopt-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span><a href=\"https://github.com/hyperopt/hyperopt\" target=\"_blank\">Hyperopt</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#XGBoost-Tuning\" data-toc-modified-id=\"XGBoost-Tuning-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><a href=\"https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\" target=\"_blank\">XGBoost Tuning</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Objective-function\" data-toc-modified-id=\"Objective-function-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Objective function</a></span></li><li><span><a href=\"#Tune-number-of-trees\" data-toc-modified-id=\"Tune-number-of-trees-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Tune number of trees</a></span></li><li><span><a href=\"#Tune-tree-specific-parameters\" data-toc-modified-id=\"Tune-tree-specific-parameters-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Tune tree-specific parameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tune-max_depth,-min_child_weight\" data-toc-modified-id=\"Tune-max_depth,-min_child_weight-2.1.3.1\"><span class=\"toc-item-num\">2.1.3.1&nbsp;&nbsp;</span>Tune max_depth, min_child_weight</a></span></li><li><span><a href=\"#Tune-gamma\" data-toc-modified-id=\"Tune-gamma-2.1.3.2\"><span class=\"toc-item-num\">2.1.3.2&nbsp;&nbsp;</span>Tune gamma</a></span></li><li><span><a href=\"#Tune-subsample,-colsample_bytree\" data-toc-modified-id=\"Tune-subsample,-colsample_bytree-2.1.3.3\"><span class=\"toc-item-num\">2.1.3.3&nbsp;&nbsp;</span>Tune subsample, colsample_bytree</a></span></li></ul></li><li><span><a href=\"#Tune-regularization-parameters\" data-toc-modified-id=\"Tune-regularization-parameters-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Tune regularization parameters</a></span></li><li><span><a href=\"#Lower-the-learning-rate-and-decide-the-optimal-parameters\" data-toc-modified-id=\"Lower-the-learning-rate-and-decide-the-optimal-parameters-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Lower the learning rate and decide the optimal parameters</a></span></li></ul></li><li><span><a href=\"#LogisticRegression-Tuning\" data-toc-modified-id=\"LogisticRegression-Tuning-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LogisticRegression Tuning</a></span></li><li><span><a href=\"#Optional-MongoTrials\" data-toc-modified-id=\"Optional-MongoTrials-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Optional <a href=\"https://hyperopt.github.io/hyperopt/scaleout/mongodb/\" target=\"_blank\">MongoTrials</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#XGBoost-Tuning\" data-toc-modified-id=\"XGBoost-Tuning-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>XGBoost Tuning</a></span></li></ul></li></ul></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжаем работать над задачей CTR-prediction с использованием датасета от Criteo.\n",
    "\n",
    "Описание задачи и данных можно посмотреть в notebook'e предыдущей практики (`sgd_logreg_nn/notebooks/ctr_prediction_mllib.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "COMMON_PATH = '/workspace/common'\n",
    "\n",
    "sys.path.append(os.path.join(COMMON_PATH, 'utils'))\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"\"\"\n",
    "--jars {common}/xgboost4j-spark-0.72.jar,{common}/xgboost4j-0.72.jar\n",
    "--py-files {common}/sparkxgb.zip pyspark-shell\n",
    "\"\"\".format(common=COMMON_PATH).replace('\\n', ' ')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"spark_sql_examples\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "from metrics import rocauc, logloss, ne, get_ate\n",
    "from processing import split_by_col\n",
    "\n",
    "from sparkxgb.xgboost import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/workspace/data/criteo'\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark** Необязательно использовать половину датасета и всего две категориальные переменные. Можно использовать больше данных, если вам позволяет ваша конфигурация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(False, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = ['_c{}'.format(i) for i in range(1, 14)]\n",
    "cat_columns = ['_c{}'.format(i) for i in range(14, 40)][:2]\n",
    "len(num_columns), len(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0, subset=num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel.load(os.path.join(DATA_PATH, 'pipeline_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1830469"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipeline_model \\\n",
    "    .transform(df) \\\n",
    "    .select(F.col('_c0').alias('label'), 'features', 'id') \\\n",
    "    .cache()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_by_col(df, 'id', [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Spark MLlib Tuning](https://spark.apache.org/docs/latest/ml-tuning.html)\n",
    "\n",
    "У имеющегося в Spark'e метода HPO есть два существенных недостатка, которые делают его мало пригодным в контексте нашей задачи:\n",
    "\n",
    "1. `ParamGridBuilder` - поиск по сетке\n",
    "2. `TrainValidationSplit` - делит данные случайнм образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Hyperopt](https://github.com/hyperopt/hyperopt)\n",
    "\n",
    "Установим `hyperopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.5 install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [XGBoost Tuning](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)\n",
    "\n",
    "> [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
    "\n",
    "### Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "    estimator = XGBoostEstimator(**space)\n",
    "    print('SPACE:', estimator._input_kwargs_processed())\n",
    "    success = False\n",
    "    attempts = 0\n",
    "    model = None\n",
    "    while not success and attempts < 2:\n",
    "        try:\n",
    "            model = estimator.fit(train_df)\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            print(e)\n",
    "            print('Try again')\n",
    "        \n",
    "    log_loss = logloss(model, val_df, probabilities_col='probabilities')\n",
    "    roc_auc = rocauc(model, val_df, probabilities_col='probabilities')\n",
    "    \n",
    "    print('LOG-LOSS: {}, ROC-AUC: {}'.format(log_loss, roc_auc))\n",
    "\n",
    "    return {'loss': log_loss, 'rocauc': roc_auc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_params = {\n",
    "    'featuresCol': \"features\", \n",
    "    'labelCol': \"label\", \n",
    "    'predictionCol': \"prediction\",\n",
    "    'eval_metric': 'logloss',\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 1,\n",
    "    'silent': 0,\n",
    "    'nworkers': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix baseline parameters and train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROL_NAME = 'xgb baseline'\n",
    "\n",
    "baseline_params = {\n",
    "    'colsample_bytree': 0.9,\n",
    "    'eta': 0.15,\n",
    "    'gamma': 0.9,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 50.0,\n",
    "    'subsample': 0.9,\n",
    "    'num_round': 20\n",
    "}\n",
    "\n",
    "baseline_model = XGBoostEstimator(**{**static_params, **baseline_params}).fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7234140746157955"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_rocauc = rocauc(baseline_model, val_df, probabilities_col='probabilities')\n",
    "baseline_rocauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_test_metrics = {\n",
    "    'logloss': logloss(baseline_model, test_df, probabilities_col='probabilities'),\n",
    "    'rocauc': rocauc(baseline_model, test_df, probabilities_col='probabilities')\n",
    "}\n",
    "\n",
    "all_metrics[CONTROL_NAME] = baseline_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune number of trees\n",
    "\n",
    "> Choose a relatively high learning rate. Generally a learning rate of 0.1 works but somewhere between 0.05 to 0.3 should work for different problems. Determine the optimum number of trees for this learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_round_choice = [10, 20, 40, 100]\n",
    "eta_choice = [0.5, 0.10, 0.15, 0.20, 0.30]\n",
    "\n",
    "space = {\n",
    "    # Optimize\n",
    "    'num_round': hp.choice('num_round', num_round_choice),\n",
    "    'eta': hp.choice('eta', eta_choice),\n",
    "    \n",
    "    # Fixed    \n",
    "    'max_depth': baseline_params['max_depth'],\n",
    "    'min_child_weight': baseline_params['min_child_weight'],\n",
    "    'subsample': baseline_params['subsample'],\n",
    "    'gamma': baseline_params['gamma'],\n",
    "    'colsample_bytree': baseline_params['colsample_bytree'],\n",
    "    \n",
    "    **static_params\n",
    "}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0, 'num_round': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на то, что в случае с `hp.choice` в переменной `best` хранится не конкретное значение гиперпараметра, а его индекс из списка, например, `num_round_choice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = eta_choice[best['eta']]  # change me!\n",
    "num_round = num_round_choice[best['num_round']]  # change me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune tree-specific parameters\n",
    "\n",
    "> Tune tree-specific parameters ( max_depth, min_child_weight, gamma, subsample, colsample_bytree) for decided learning rate and number of trees. Note that we can choose different parameters to define a tree and I’ll take up an example here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune max_depth, min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune subsample, colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune regularization parameters\n",
    "\n",
    "> Tune regularization parameters (lambda, alpha) for xgboost which can help reduce model complexity and enhance performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower the learning rate and decide the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## LogisticRegression Tuning\n",
    "\n",
    "Подберем гиперпараметры для логрега из предыдущих практик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Optional [MongoTrials](https://hyperopt.github.io/hyperopt/scaleout/mongodb/)\n",
    "\n",
    "> For parallel search, hyperopt includes a MongoTrials implementation that supports asynchronous updates.\n",
    "\n",
    "**TLDR** Преимущества использования `MongoTrials`:\n",
    "* `MongoTrials` позволяет параллельно запускать несколько вычислений целевой функции\n",
    "* Динамический уровень параллелизма - можно добавлять/удалять воркеров, которые вычисляют целевую функцию\n",
    "* Все результаты сохраняются в БД - история запусков никуда не потеряется\n",
    "\n",
    "*За выполнение данного задания можно получить дополнительно +0.4 к итоговому баллу*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Подведем итоги.\n",
    "\n",
    "Обучите модели с найденными (оптимальными) гиперпараметрами и сделайте справнение на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая таблица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>xgb opt ate %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logloss</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rocauc</td>\n",
       "      <td>-1.554312e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    metric  xgb opt ate %\n",
       "0  logloss   0.000000e+00\n",
       "1   rocauc  -1.554312e-13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ate(all_metrics, CONTROL_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
