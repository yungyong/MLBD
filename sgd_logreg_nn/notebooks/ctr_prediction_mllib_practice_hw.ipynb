{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CTR-prediction\" data-toc-modified-id=\"CTR-prediction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CTR-prediction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Problem-Formulation\" data-toc-modified-id=\"Problem-Formulation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Problem Formulation</a></span></li><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset-construction:\" data-toc-modified-id=\"Dataset-construction:-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Dataset construction:</a></span></li><li><span><a href=\"#Format:\" data-toc-modified-id=\"Format:-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Format:</a></span></li></ul></li><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Metrics</a></span></li></ul></li><li><span><a href=\"#Dataset-preprocessing\" data-toc-modified-id=\"Dataset-preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#ML-Pipelines-(Transformers,-Estimators)\" data-toc-modified-id=\"ML-Pipelines-(Transformers,-Estimators)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html#pipeline-components\" target=\"_blank\">ML Pipelines (Transformers, Estimators)</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-stages-of-pipeline\" data-toc-modified-id=\"Prepare-stages-of-pipeline-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Prepare stages of pipeline</a></span></li><li><span><a href=\"#Fit-and-save-pipeline\" data-toc-modified-id=\"Fit-and-save-pipeline-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Fit and save pipeline</a></span></li><li><span><a href=\"#Load-fitted-pipeline\" data-toc-modified-id=\"Load-fitted-pipeline-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Load fitted pipeline</a></span></li><li><span><a href=\"#Transform-dataset-using-pipeline\" data-toc-modified-id=\"Transform-dataset-using-pipeline-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Transform dataset using pipeline</a></span></li><li><span><a href=\"#Make-dataset-split\" data-toc-modified-id=\"Make-dataset-split-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Make dataset split</a></span></li></ul></li></ul></li><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html\" target=\"_blank\">Classification</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression\" target=\"_blank\">Logistic Regression</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-and-Train-model\" data-toc-modified-id=\"Define-and-Train-model-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Define and Train model</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html\" target=\"_blank\">Evaluation</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-classification-metrics\" data-toc-modified-id=\"Binary-classification-metrics-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html#binary-classification\" target=\"_blank\">Binary classification metrics</a></a></span></li><li><span><a href=\"#Make-submission\" data-toc-modified-id=\"Make-submission-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Make submission</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTR-prediction\n",
    "\n",
    "## Problem Formulation\n",
    "\n",
    "$\\newcommand{\\vecw}{{\\bf w}}$\n",
    "$\\newcommand{\\vecx}{{\\bf x}}$\n",
    "\n",
    "* Dataset: $X^N = \\{ z_i \\}^N_{i=1}$, где $z_i = (\\vecx_i, y_i) \\sim P(z), y_i \\in \\{0,1\\}$\n",
    "* Prediction: $$ \\hat{y}_i = f_{\\vecw}(\\vecx_i) =  \\mathbb{P} \\left\\{ y = 1 \\mid \\vecx_i \\right\\} $$\n",
    "* Loss function (Binary Cross-Entropy): $$ \\min\\limits_{\\vecw} \\quad \\frac{\\lambda}{2}\\| \\vecw \\|^2_2 - \\frac{1}{N} \\sum\\limits_{i=1}^{N} y_i \\log \\hat{y}_i + (1-y_i) \\log(1-\\hat{y}_i) $$\n",
    "\n",
    "## Dataset\n",
    "$ $\n",
    "<details>\n",
    "  <summary>Click here to see the details</summary>\n",
    "\n",
    "For more details see `/data/criteo/readme.txt`\n",
    "\n",
    "### Dataset construction:\n",
    "\n",
    "\n",
    ">There are 13 features taking **integer** values and 26\n",
    "**categorical** features. The values of the categorical features have been hashed\n",
    "onto 32 bits for anonymization purposes. \n",
    "Some features may have missing values.\n",
    "\n",
    "> The rows are chronologically ordered by `id` column.\n",
    "\n",
    "> The test set corresponds to events on the day following the training period. \n",
    "The first column (`label`) has been removed.\n",
    "\n",
    "\n",
    "### Format:\n",
    "\n",
    "> The columns are comma separeted with the following schema:\n",
    "`<label>,<integer feature 1>, ... <integer feature 13>,<categorical feature 1>, ... <categorical feature 26>,<id>`\n",
    "\n",
    "> When a value is missing, the field is \"\". There is no `label` field in the test set.\n",
    "\n",
    "</details>\n",
    "    \n",
    "## Metrics\n",
    "\n",
    "The evaluation metrics for this task are\n",
    "* ROC AUC\n",
    "* LogLoss\n",
    "* [Normalized Entropy](https://quinonero.net/Publications/predicting-clicks-facebook.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"spark_sql_examples\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/workspace/data/criteo'\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin our introduction to Spark [MLlib](https://spark.apache.org/docs/latest/ml-guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset preprocessing\n",
    "\n",
    "Before we can train any prediction model on our dataset we need to conver each row into real-valued features vector ($\\vecx \\in \\mathbb{R}^n$).\n",
    "\n",
    "Spark MLlib provides easy to use tools for preprocessing raw features and turning them into suitable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to fix the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = df.sample(False, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.select('id').toPandas().to_csv('./sample_ids.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_ids = spark.createDataFrame(pd.read_csv('./sample_ids.csv')[['id']])\n",
    "\n",
    "df = df.join(\n",
    "        sample_ids,\n",
    "        on='id',\n",
    "        how='inner'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only first two categorical features for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_feats = df.columns[2:15]\n",
    "hash_feats = df.columns[15:]\n",
    "label = df.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df\\\n",
    "    .fillna(0, subset=cnt_feats)\\\n",
    "    .fillna('none', subset=hash_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: string (nullable = false)\n",
      " |-- _c15: string (nullable = false)\n",
      " |-- _c16: string (nullable = false)\n",
      " |-- _c17: string (nullable = false)\n",
      " |-- _c18: string (nullable = false)\n",
      " |-- _c19: string (nullable = false)\n",
      " |-- _c20: string (nullable = false)\n",
      " |-- _c21: string (nullable = false)\n",
      " |-- _c22: string (nullable = false)\n",
      " |-- _c23: string (nullable = false)\n",
      " |-- _c24: string (nullable = false)\n",
      " |-- _c25: string (nullable = false)\n",
      " |-- _c26: string (nullable = false)\n",
      " |-- _c27: string (nullable = false)\n",
      " |-- _c28: string (nullable = false)\n",
      " |-- _c29: string (nullable = false)\n",
      " |-- _c30: string (nullable = false)\n",
      " |-- _c31: string (nullable = false)\n",
      " |-- _c32: string (nullable = false)\n",
      " |-- _c33: string (nullable = false)\n",
      " |-- _c34: string (nullable = false)\n",
      " |-- _c35: string (nullable = false)\n",
      " |-- _c36: string (nullable = false)\n",
      " |-- _c37: string (nullable = false)\n",
      " |-- _c38: string (nullable = false)\n",
      " |-- _c39: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ML Pipelines (Transformers, Estimators)](https://spark.apache.org/docs/latest/ml-pipeline.html#pipeline-components)\n",
    "\n",
    "\n",
    "MLlib standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline, or workflow.\n",
    "\n",
    "* `Transformer`: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.\n",
    "\n",
    "\n",
    "* `Estimator`: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.\n",
    "\n",
    "\n",
    "* `Pipeline`: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n",
    "\n",
    "---\n",
    "Basically speaking `transformer` is an instance of class that implements `transform` method, and both `estimator` and `pipeline` implements `transform` and `fit` methods.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare stages of pipeline\n",
    "\n",
    "We might benefit from using `StringIndexer, OneHotEncoderEstimator, VectorAssembler` (see [doc](https://spark.apache.org/docs/latest/ml-features) for details) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept behind String Indexing is very intuitive. We simply replace each category with a number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=col, outputCol=col+'_index') for col in hash_feats]\n",
    "\n",
    "ohe = OneHotEncoderEstimator(\n",
    "    inputCols=[col+'_index' for col in hash_feats[:3]], \n",
    "    outputCols=[col+'_ohe' for col in hash_feats[:3]]\n",
    ")\n",
    "\n",
    "ohe_assembler = VectorAssembler(inputCols=[col+'_ohe' for col in hash_feats[:3]], outputCol='ohe_features')\n",
    "\n",
    "num_assembler = VectorAssembler(inputCols=cnt_feats, outputCol=\"num_features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"num_features\", outputCol=\"scaled_features\")\n",
    "\n",
    "final_assembler = VectorAssembler(inputCols=['scaled_features', 'ohe_features'], outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline  = Pipeline(stages=indexers + [ohe, ohe_assembler, num_assembler, scaler, final_assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = pipeline.fit(df)\n",
    "pm.save(\"/pipeline_model_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fitted pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_l = PipelineModel.load(\"/pipeline_model_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dataset using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = pm_l.transform(df)\n",
    "\n",
    "transformed_data = transformed_data.select('features', 'id', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- _c0: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.write.parquet('trans_data_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+---+\n",
      "|            features|   id|_c0|\n",
      "+--------------------+-----+---+\n",
      "|(149520,[2,3,4,5,...|49586|  1|\n",
      "|(149520,[1,2,4,5,...|49967|  0|\n",
      "|(149520,[1,2,3,4,...|52611|  0|\n",
      "+--------------------+-----+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset split\n",
    "\n",
    "Spark provides [randomSplit](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit) method.\n",
    "\n",
    "It is not the best choice in our task since we have chronological order in data.\n",
    "\n",
    "We need to implement our own split function which will split the data in parts with respect to chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_col(df, split_col, parts_fractions, N):\n",
    "    \"\"\"\n",
    "    df - DataFrame\n",
    "    split_col - total order column\n",
    "    parts_fractions - fractions of resulting parts\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.sort(split_col, ascending=True)\n",
    "    \n",
    "    rdd_df = df.select(split_col).rdd.zipWithIndex()\n",
    "    df_final = rdd_df.toDF()\n",
    "    df_final = df_final\\\n",
    "        .withColumn(split_col, df_final['_1'].getItem(split_col))\\\n",
    "        .drop('_1')\n",
    "    \n",
    "    df_final = df.join(\n",
    "                        df_final.withColumnRenamed('_1', 'id'),\n",
    "                        how='left',\n",
    "                        on=split_col\n",
    "                        )\n",
    "    \n",
    "    train, val = round(parts_fractions[0] * N), round(sum(parts_fractions[:2]) * N)\n",
    "\n",
    "    \n",
    "    parts = []\n",
    "    \n",
    "    df_final = df_final.sort(split_col, ascending=True)\\\n",
    "        .withColumnRenamed('_2', 'idx_row')\\\n",
    "        .withColumn('fractions', \n",
    "                    F.when(F.col('idx_row') < F.lit(train), 'train')\\\n",
    "                        .otherwise(F.when((F.col('idx_row') >= F.lit(train)) & (F.col('idx_row') < F.lit(val)), 'val')\\\n",
    "                                   .otherwise('test'))\n",
    "                   )\n",
    "    parts = [df_final\\\n",
    "             .filter(F.col('fractions') == F.lit(frac)) for frac in ['train', 'val', 'test']]\n",
    "    \n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = transformed_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_by_col(transformed_data, 'id', [0.8, 0.1, 0.1], N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.1, 0.1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count() / N, val_df.count() / N, test_df.count() / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293360"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---+-------+---------+\n",
      "|          id|            features|_c0|idx_row|fractions|\n",
      "+------------+--------------------+---+-------+---------+\n",
      "|455266621063|(149520,[0,1,2,3,...|  1| 293360|      val|\n",
      "|455266621067|(149520,[1,4,5,6,...|  0| 293361|      val|\n",
      "|455266621132|(149520,[2,4,5,6,...|  0| 293362|      val|\n",
      "+------------+--------------------+---+-------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, features: vector, _c0: int, idx_row: bigint, fractions: string]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.cache()\n",
    "val_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# [Classification](https://spark.apache.org/docs/latest/ml-classification-regression.html)\n",
    "\n",
    "## [Logistic Regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression)\n",
    "\n",
    "### Define and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression \n",
    "lr_model = LogisticRegression(featuresCol='features', labelCol=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "модель училась ровно 2 часа\n",
    "\n",
    "293360 примеров\n",
    "\n",
    "и пришлось поставить (\"spark.driver.memory\", \"4g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fitted = lr_model.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fitted.save(os.path.join(DATA_PATH, 'logreg.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LogisticRegressionModel.load(os.path.join(DATA_PATH, 'logreg.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_pred = final_model.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_pred = final_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---+-------+---------+--------------------+--------------------+----------+\n",
      "|          id|            features|_c0|idx_row|fractions|       rawPrediction|         probability|prediction|\n",
      "+------------+--------------------+---+-------+---------+--------------------+--------------------+----------+\n",
      "|455266621063|(149520,[0,1,2,3,...|  1| 293360|      val|[-0.1571897065234...|[0.46078328931603...|       1.0|\n",
      "|455266621067|(149520,[1,4,5,6,...|  0| 293361|      val|[0.90381419637698...|[0.71173269004843...|       0.0|\n",
      "|455266621132|(149520,[2,4,5,6,...|  0| 293362|      val|[2.06544360603564...|[0.88749883245489...|       0.0|\n",
      "|455266621136|(149520,[0,1,3,4,...|  0| 293363|      val|[1.49746315413032...|[0.81719580976793...|       0.0|\n",
      "|455266621151|(149520,[1,4,6,10...|  0| 293364|      val|[3.26033633883637...|[0.96304276333765...|       0.0|\n",
      "+------------+--------------------+---+-------+---------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_df_pred.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# [Evaluation](https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html)\n",
    "\n",
    "## [Binary classification metrics](https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html#binary-classification)\n",
    "\n",
    "* ROC AUC\n",
    "* LogLoss\n",
    "* Normalized Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "second_el = udf(lambda v: float(v[1]), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "def rocauc(model, df, label_name):\n",
    "    \n",
    "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=label_name)\n",
    "    \n",
    "    return evaluator.evaluate(model.transform(df), {evaluator.metricName: \"areaUnderROC\"})\n",
    "    \n",
    "\n",
    "\n",
    "def logloss(model, df, label_name):\n",
    "    #-(yt log(yp) + (1 - yt) log(1 - yp))\n",
    "    \n",
    "    df1 = model.transform(df)\\\n",
    "        .withColumn('logloss', -(F.col(label_name) * F.log(second_el('probability'))\\\n",
    "                       + (1 -  F.col(label_name)) * F.log(1 - second_el('probability'))) \n",
    "                   )\\\n",
    "        .select(F.mean('logloss').alias('logloss'))\n",
    "\n",
    "    \n",
    "    return df1.take(1)[0]['logloss']\n",
    "\n",
    "\n",
    "def ne(df, logloss, label_name):\n",
    "    \n",
    "    mean_lit = df\\\n",
    "        .select(F.mean(label_name).alias('mean_lab')).take(1)[0]['mean_lab']\n",
    "    \n",
    "    mean_logloss = -(mean_lit * np.log(mean_lit) + (1 - mean_lit)*np.log(1 - mean_lit))\n",
    "        \n",
    "    return logloss / mean_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789764836462141"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(final_model, test_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6447082898932033"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocauc(final_model, test_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3437496925855579"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne(test_df, 0.7789764836462141, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission\n",
    "\n",
    "Join the [competition](https://www.kaggle.com/c/mlbd-20-ctr-prediction-1) and make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/workspace/data/criteo'\n",
    "\n",
    "TEST_PATH = os.path.join(DATA_PATH, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = TEST\\\n",
    "    .fillna(0, subset=cnt_feats)\\\n",
    "    .fillna('none', subset=hash_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### сколько категорий отсутсвтвуют в трейне и в обученных пайплайнах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_c14\n",
      "[Row(count(DISTINCT _c14)=1240)] [Row(count(DISTINCT _c14)=909)]\n",
      "_c15\n",
      "[Row(count(DISTINCT _c15)=547)] [Row(count(DISTINCT _c15)=536)]\n",
      "_c16\n",
      "[Row(count(DISTINCT _c16)=324499)] [Row(count(DISTINCT _c16)=148065)]\n"
     ]
    }
   ],
   "source": [
    "for col in hash_feats[:3]:\n",
    "    print(col)\n",
    "    print(TEST.select(F.countDistinct(col)).take(1), df.select(F.countDistinct(col)).take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_invalid_keep(df, sample, col):\n",
    "    \"\"\"заменяет незнакомые значения на 'none'\"\"\"\n",
    "    \n",
    "    print('column', col)\n",
    "    print('data count distinct', df.select(F.countDistinct(col).alias('cd')).take(1)[0]['cd'], \n",
    "          'sample count distinct', sample.select(F.countDistinct(col).alias('cd')).take(1)[0]['cd'])\n",
    "    \n",
    "    sample = sample.select(col).drop_duplicates().withColumn('keep', F.lit(1))\n",
    "    df = df.join(\n",
    "                sample,\n",
    "                on=col,\n",
    "                how='left'\n",
    "            )\\\n",
    "        .fillna(0, subset=['keep'])\\\n",
    "        .withColumnRenamed(col, col+'_old')\\\n",
    "        .withColumn(col, \n",
    "                    F.when(F.col('keep') == F.lit(1), F.col(col+'_old'))\\\n",
    "                        .otherwise('none')\n",
    "                   )\\\n",
    "        .drop(col+'_old', 'keep')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_invalid_skip(df, col):\n",
    "    \"\"\"удаляет незнакомые значения\"\"\"\n",
    "    \n",
    "    print('size before', df.count())\n",
    "    df1 = df.filter(F.col(col) != F.lit('none'))\n",
    "    print('size after', df1.count())\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column _c14\n",
      "data count distinct 1240 sample count distinct 909\n",
      "column _c15\n",
      "data count distinct 547 sample count distinct 536\n",
      "column _c16\n",
      "data count distinct 324499 sample count distinct 148065\n"
     ]
    }
   ],
   "source": [
    "for col in   hash_feats[:3]:  \n",
    "    TEST = handle_invalid_keep(TEST, df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_c14\n",
      "[Row(count(DISTINCT _c14)=828)] [Row(count(DISTINCT _c14)=909)]\n",
      "_c15\n",
      "[Row(count(DISTINCT _c15)=529)] [Row(count(DISTINCT _c15)=536)]\n",
      "_c16\n",
      "[Row(count(DISTINCT _c16)=26291)] [Row(count(DISTINCT _c16)=148065)]\n"
     ]
    }
   ],
   "source": [
    "for col in hash_feats[:3]:\n",
    "    print(col)\n",
    "    print(TEST.select(F.countDistinct(col)).take(1), df.select(F.countDistinct(col)).take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_skipped = TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size before 917961\n",
      "size after 917027\n",
      "size before 917027\n",
      "size after 916406\n",
      "size before 916406\n",
      "size after 539934\n"
     ]
    }
   ],
   "source": [
    "for col in   hash_feats[:3]:  \n",
    "    TEST_skipped = handle_invalid_skip(TEST_skipped, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### только к 60% данных из теста можно применить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_TEST = pm_l.transform(TEST_skipped.select(*hash_feats[:3], *cnt_feats, 'id'))\n",
    "\n",
    "transformed_TEST = transformed_TEST.select('features', 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|            features|          id|       rawPrediction|         probability|prediction|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "|(149520,[0,1,2,3,...|704375096151|[11.1356513272780...|[0.99998541717235...|       0.0|\n",
      "|(149520,[1,2,4,5,...|661425083742|[11.5303190800824...|[0.99999017252877...|       0.0|\n",
      "|(149520,[1,2,3,4,...|575525906360|[11.5606574813648...|[0.99999046619843...|       0.0|\n",
      "|(149520,[2,4,5,6,...|575525934899|[11.5700106962885...|[0.99999055495357...|       0.0|\n",
      "|(149520,[1,2,4,5,...|618475422405|[12.2145288630303...|[0.99999504212740...|       0.0|\n",
      "|(149520,[1,2,3,4,...|618475423709|[11.5011491787689...|[0.99998988164338...|       0.0|\n",
      "|(149520,[1,2,3,4,...|618475575902|[11.3393488245236...|[0.99998810462299...|       0.0|\n",
      "|(149520,[1,4,7,8,...|618475686165|[11.6380256759929...|[0.99999117599315...|       0.0|\n",
      "|(149520,[1,2,3,4,...|627065405260|[11.2755798930932...|[0.99998732136889...|       0.0|\n",
      "|(149520,[0,1,2,3,...|635655230199|[10.8186342465748...|[0.99997997750705...|       0.0|\n",
      "+--------------------+------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_TEST = q1.transform(transformed_TEST)\n",
    "\n",
    "pred_TEST.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### средний таргет на предсказаниях 0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(prediction)=0.11114506587842218)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_TEST.select(F.mean(F.col('prediction'))).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### средний таргет на трейне 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* заполнение оставшихся 40% данных средним таргетом из трейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lit = 0.2543632397054813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_const = TEST.filter((F.col('_c14') == 'none') | (F.col('_c15') == 'none') | (F.col('_c16') == 'none'))\\\n",
    "    .withColumn('proba', F.lit(mean_lit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pred_TEST\\\n",
    "    .select('id', second_el('probability').alias('proba'))\\\n",
    "    .union(TEST_const.select('id', 'proba'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort('id').toPandas().to_csv('./answers.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
